import os
import pandas as pd
from snakemake.utils import min_version

###################################################################################

#NOTES:

#snakemake \
#    --use-conda \
#    --cluster 'qsub -V -cwd -S /bin/bash -pe smp {threads} -o {log}.log -j y -q all.q' \
#    --jobs 20 \
#    --latency-wait 200 \
#    --rerun-incomplete \
#    --keep-going \
#    --snake code/process_seq_data.snake 

#using
# - snakemake v6.12.1
# - using conda v4.10.3

# a small modification needs to be made to the rsync code to get data from ncbi
# To resolve the error "rsync_from_ncbi.pl: unexpected FTP path (new server?)"
# replace in the file "libexec/rsync_from_ncbi.pl " "^ftp://" by "^https:// " in line 46.

# nano ~/miniconda3/envs/pathogen_probes-process_seq_data/libexec/rsync_from_ncbi.pl

###################################################################################
##### set minimum snakemake version #####
min_version("6.12.1")

#set main project dir and work from there
proj_dir    = "/master/nplatt/pathogen_probes"
data_dir    = "{}/data".format(proj_dir)
results_dir = "{}/results".format(proj_dir)
envs_dir    = "{}/env".format(proj_dir)
logs_dir    = "{}/logs".format(results_dir)

#get sample info
samples_df  = pd.read_csv("{}/seq_data/sample_info.csv".format(data_dir))
samples     = list(samples_df["sample_id"])

localrules:
    all,

rule all:
    input:
        expand("{dir}/seq_data/{id}_{read}.fastq.gz", dir  = data_dir,
                                                      id   = samples, 
                                                      read = ["R1", "R2"] ),
        expand("{dir}/filtered_reads/{id}_filtered_{read}.fq.gz", dir  = results_dir,
                                                                  id   = samples,
                                                                  read = ["R1", "R2"]),
        expand("{dir}/fastqc/{id}_{read}_fastqc.{ext}", dir  = results_dir, 
                                                        id   = samples, 
                                                        read = ["R1", "R2"],
                                                        ext  = ["zip", "html"] ),
        expand("{dir}/control_kraken2/{id}_kraken_report_conf{conf}.tbl", dir  = results_dir,
                                                                          id   = samples,
                                                                          conf = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 
                                                                                  0.6, 0.7, 0.8, 0.9, 1.0]),
        expand("{dir}/control_kraken2/{id}_kraken_per_read_info_conf{conf}.tsv", dir  = results_dir,
                                                                                 id   = samples,
                                                                                 conf = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 
                                                                                         0.6, 0.7, 0.8, 0.9, 1.0]),
        expand("{dir}/bbmap/{id}_vs_{ref}{ext}", dir = results_dir,
                                                  id  = samples,
                                                  ref = ["sch_bov", "sch_man", "myc_bov", "myc_tub",
                                                         "pla_fal", "pla_viv", "mus_mus", "hom_sap" ],
                                                  ext = ["-MAPPED.fas", "-UNMAPPED.fas", ".bam"]),
        expand("{dir}/bbmap/{id}_vs_{ref}.sorted.bam", dir = results_dir,
                                                       id  = samples,
                                                       ref = ["sch_bov", "sch_man", "myc_bov", "myc_tub",
                                                              "pla_fal", "pla_viv", "mus_mus", "hom_sap" ]),
        expand("{dir}/bbmap/{id}_vs_{ref}.sorted.bam.bai", dir = results_dir,
                                                           id  = samples,
                                                           ref = ["sch_bov", "sch_man", "myc_bov", "myc_tub",
                                                                  "pla_fal", "pla_viv", "mus_mus", "hom_sap" ]),
        expand("{dir}/mosdepth/{id}_vs_{ref}.regions.bed.gz", dir = results_dir,
                                                           id  = samples,
                                                           ref = ["sch_bov", "sch_man", "myc_bov", "myc_tub",
                                                                  "pla_fal", "pla_viv", "mus_mus", "hom_sap" ])



rule filter_reads:
    input:
        r1           = data_dir + "/seq_data/{id}_R1.fastq.gz",
        r2           = data_dir + "/seq_data/{id}_R2.fastq.gz",
        adapter_file = data_dir + "/adapters.fas"
    output:
        r1_pe = results_dir + "/filtered_reads/{id}_filtered_R1.fq.gz",
        r2_pe = results_dir + "/filtered_reads/{id}_filtered_R2.fq.gz",
        r1_se = temp(results_dir + "/filtered_reads/{id}_filtered_R1_SE.fq.gz"),
        r2_se = temp(results_dir + "/filtered_reads/{id}_filtered_R2_SE.fq.gz"),
        rx_se = results_dir + "/filtered_reads/{id}_filtered_RX.fq.gz"
    threads:
        4
    log:
        logs_dir + "/filter_reads#{id}"
    conda:
        envs_dir + "/pathogen_probes-trimmomatic.yml"
    shell:
        """
        trimmomatic \
            PE \
            -threads {threads} \
            -phred33 \
            {input.r1} \
            {input.r2} \
            {output.r1_pe} \
            {output.r1_se} \
            {output.r2_pe} \
            {output.r2_se} \
            LEADING:10 \
            TRAILING:10 \
            SLIDINGWINDOW:4:15 \
            MINLEN:36 \
            ILLUMINACLIP:{input.adapter_file}:2:30:10:1:true

        zcat {output.r1_se} {output.r2_se} | gzip >{output.rx_se} 
        """

rule fastqc:
    input:
        r1   = data_dir + "/seq_data/{id}_R1.fastq.gz",
        r2   = data_dir + "/seq_data/{id}_R2.fastq.gz"
    output:
        results_dir + "/fastqc/{id}_R1_fastqc.zip",
        results_dir + "/fastqc/{id}_R2_fastqc.zip",
        results_dir + "/fastqc/{id}_R1_fastqc.html",
        results_dir + "/fastqc/{id}_R2_fastqc.html"
    threads:
        4
    log:
        logs_dir + "/fastqc#{id}"
    conda:
        envs_dir + "/pathogen_probes-fastqc.yml"
    shell:
        """
        fastqc \
            -o {results_dir}/fastqc \
            -t {threads} \
            -f fastq \
            {input.r1} \
            {input.r2}
        """

rule kraken:
    input:
        r1_pe = results_dir + "/filtered_reads/{id}_filtered_R1.fq.gz",
        r2_pe = results_dir + "/filtered_reads/{id}_filtered_R2.fq.gz"
    output:
        report = results_dir + "/control_kraken2/{id}_kraken_report_conf{conf}.tbl",
        table  = results_dir + "/control_kraken2/{id}_kraken_per_read_info_conf{conf}.tsv"
    params:
        kraken_db="results/control_kraken2/control_kraken2_db"
    threads:
        4
    log:
        logs_dir + "/kraken_{conf}#{id}"
    conda:
        envs_dir + "/pathogen_probes-kraken2_clean.yml"
    shell:
        """
        kraken2 \
            --use-names \
            --threads {threads} \
            --db {params.kraken_db} \
            --report {output.report} \
            --paired \
            --confidence {wildcards.conf} \
            --output {output.table} \
            --report-zero-counts \
            {input.r1_pe} \
            {input.r2_pe}
        """

rule bbmap_index:
    input:
        genome = results_dir + "/genomes/{ref}.fas",
    output:
        touch_file  = results_dir + "/genomes/bbmap_index_{ref}.done",
    params:
        build = "1",
        path = results_dir + "/genomes/{ref}"
    threads:
        1
    log:
        logs_dir + "/bbmap_index#{ref}.log"
    conda:
        envs_dir + "/pathogen_probes-bbmap.yml"
    shell:
        """
        bbmap.sh \
            ref={input.genome} \
            path={params.path} \
            build={params.build} \
            >{log} 2>&1 \
        
        touch {output.touch_file}
        """

rule bbmap:
    input:
        genome = results_dir + "/genomes/{ref}.fas",
        r1_pe  = results_dir + "/filtered_reads/{id}_filtered_R1.fq.gz",
        r2_pe  = results_dir + "/filtered_reads/{id}_filtered_R2.fq.gz"
    output:
        mapped_fas   = results_dir + "/bbmap/{id}_vs_{ref}-MAPPED.fas",
        unmapped_fas = results_dir + "/bbmap/{id}_vs_{ref}-UNMAPPED.fas",
        bam          =  results_dir + "/bbmap/{id}_vs_{ref}.bam"
    params:
        build = "1",
        path = results_dir + "/genomes/{ref}"
    threads:
        4
    log:
        logs_dir + "/bbmap#{id}_vs_{ref}.log"
    conda:
        envs_dir + "/pathogen_probes-bbmap.yml"
    shell:
        """
    bbmap.sh \
        path={params.path} \
        build={params.build} \
        in={input.r1_pe} \
        in2={input.r2_pe} \
        touppercase=t \
        slow=t \
        minid=0.8 \
        threads={threads} \
        ambiguous=all \
        out={output.bam} \
        outu={output.unmapped_fas}\
        outm={output.mapped_fas} \
        overwrite=t \
        -Xmx100g \
        >{log} 2>&1
        """

rule sort_bam:
    input:
        results_dir + "/bbmap/{id}_vs_{ref}.bam"
    output:
        results_dir + "/bbmap/{id}_vs_{ref}.sorted.bam"
    threads:
        4
    log:
        logs_dir + "/sort_bam#{id}_vs_{ref}.log"
    conda:
        envs_dir + "/pathogen_probes-samtools.yml"
    shell:
        """
        samtools sort -O BAM -o {output} {input}
        """

rule index_bam:
    input:
        results_dir + "/bbmap/{id}_vs_{ref}.sorted.bam"
    output:
        results_dir + "/bbmap/{id}_vs_{ref}.sorted.bam.bai"
    threads:
        1
    log:
        logs_dir + "/index_bam#{id}_{ref}.log",
    conda:
        envs_dir + "/pathogen_probes-samtools.yml"
    shell:
        """
        samtools index {input}
        """

rule prep_probe_bed:
    input:
        results_dir + "/probe_coords.bed"
    output:
        results_dir + "/loci_coords.bed"
    threads:
        4
    log:
        logs_dir + "/prep_probe_bed.log",
    conda:
        envs_dir + "/pathogen_probes-bedtools.yml"
    shell:
        """
        bedtools sort -i results/probe_coords.bed | bedtools merge -i - -d 0 >results/loci_coords.bed
        """

rule mosdepth:
    input:
        bai = results_dir + "/bbmap/{id}_vs_{ref}.sorted.bam.bai",
        bam = results_dir + "/bbmap/{id}_vs_{ref}.sorted.bam",
        bed = results_dir + "/loci_coords.bed"
    output:
        temp(results_dir + "/mosdepth/{id}_vs_{ref}.mosdepth.global.dist.txt"),
        temp(results_dir + "/mosdepth/{id}_vs_{ref}.mosdepth.region.dist.txt"),
        temp(results_dir + "/mosdepth/{id}_vs_{ref}.regions.bed.gz.csi"),
        temp(results_dir + "/mosdepth/{id}_vs_{ref}.mosdepth.summary.txt"),
        results_dir + "/mosdepth/{id}_vs_{ref}.regions.bed.gz"
    threads:
        4
    params:
        prefix = results_dir + "/mosdepth/{id}_vs_{ref}"
    log:
        logs_dir + "/mosdepth#{id}_vs_{ref}.log",
    conda:
        envs_dir + "/pathogen_probes-mosdepth.yml"
    shell:
        """
        mosdepth \
            --threads {threads} \
            --by {input.bed}  \
            --no-per-base \
            {params.prefix} \
            {input.bam} \
            >{log} 2>&1
        """

#start processing in jupyter notebook