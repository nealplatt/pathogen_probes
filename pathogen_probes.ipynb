{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import wget\n",
    "import glob\n",
    "\n",
    "from collections import defaultdict\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "os.chdir(\"/master/nplatt/pathogen_probes/\")\n",
    "\n",
    "major_groups = [ \"anaplasma\",         \"apicomplexa\",       \"bacillus\",         \"bartonella\",       \n",
    "                 \"borrelia\",          \"burkholderia\",      \"campylobacter\",    \"cestoda\",         \n",
    "                 \"chlamydia\",         \"coxiella\",          \"ehrlichia\",        \"eurotiales\",     \n",
    "                 \"francisella\",       \"hexamitidae\",       \"kinetoplastea\",    \"leptospira\",\n",
    "                 \"listeria\",          \"mycobacterium\",     \"nematoda-clade1\",  \"nematoda-clade3\",\n",
    "                 \"nematoda-clade4a\",  \"nematoda-clade4b\",  \"nematoda-clade5\",  \"onygenales\",\n",
    "                 \"pasteurella\",       \"rickettsia\",        \"salmonella\",       \"streptobacillus\",\n",
    "                 \"trematoda\",         \"tremellales\",       \"trypanosoma\",      \"yersinia\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build probes via for each group via Phyluce\n",
    "\n",
    "Run the phyluce pipleine that is embeded in taxon specific notebooks.\n",
    "\n",
    " - phyluce_probes_bact_ana-cam.ipynb\n",
    " - phyluce_probes_bact_chl-list.ipynb\n",
    " - phyluce_probes_bact_myc-yer.ipynb\n",
    " - phyluce_probes_euka.ipynb\n",
    " - phyluce_probes_euka-nematodes.ipynb\n",
    " \n",
    " ** THESE NOTEBOOKS ARE RUN WITH THE ```pathogen_probes-phyluce``` ENVIRONMENT **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify target 50 loci and associated probes per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anaplasma 368\n",
      "apicomplexa 3144\n",
      "bacillus 834\n",
      "bartonella 1799\n",
      "borrelia 685\n",
      "burkholderia 683\n",
      "campylobacter 2198\n",
      "cestoda 902\n",
      "chlamydia 832\n",
      "coxiella 144\n",
      "ehrlichia 235\n",
      "eurotiales 3766\n",
      "francisella 471\n",
      "hexamitidae 782\n",
      "kinetoplastea 2914\n",
      "leptospira 2522\n",
      "listeria 767\n",
      "mycobacterium 2464\n",
      "nematoda-clade1 356\n",
      "nematoda-clade3 1468\n",
      "nematoda-clade4a 252\n",
      "nematoda-clade4b 1596\n",
      "nematoda-clade5 3138\n",
      "onygenales 1892\n",
      "pasteurella 616\n",
      "rickettsia 395\n",
      "salmonella 145\n",
      "streptobacillus 245\n",
      "trematoda 914\n",
      "tremellales 1957\n",
      "trypanosoma 616\n",
      "yersinia 225\n"
     ]
    }
   ],
   "source": [
    "#get 50 loci with the fewest numbers of probes\n",
    "if os.path.exists(\"results/phyluce/targeted_probes\"):\n",
    "    shutil.rmtree(\"results/phyluce/targeted_probes\")\n",
    "\n",
    "os.makedirs(\"results/phyluce/targeted_probes\")\n",
    "\n",
    "for group in major_groups:\n",
    "    in_clust_fas = \"results/phyluce/{}/final_probe_design/{}_v1-master_probe_list.95P_cdhit\".format( group, \n",
    "                                                                                                     group )\n",
    "    \n",
    "    #count number of probes per locus\n",
    "    #read in the sequences\n",
    "    seq_records = list(SeqIO.parse(in_clust_fas, \"fasta\"))\n",
    "    \n",
    "    locus_counts = defaultdict(int)\n",
    "    locus_names = {}\n",
    "    \n",
    "    #loop through the sequences and count the number of probes per locus\n",
    "    for seq in seq_records:\n",
    "        locus=seq.name.split(\"_\")[2]\n",
    "        locus_counts[locus] = locus_counts[locus] + 1\n",
    "    \n",
    "    #get top 50 \n",
    "    fifty_loci = sorted(locus_counts.items(), key=lambda x: x[1])[0:49]\n",
    "    \n",
    "    #count number of probes per group\n",
    "    targeted_loci = []\n",
    "    num_group_probes = 0\n",
    "    \n",
    "    for locus in fifty_loci:\n",
    "        num_group_probes = num_group_probes + locus[1]\n",
    "        targeted_loci.append(locus[0])\n",
    "    \n",
    "    print(group + \" \" + str(num_group_probes))\n",
    "    \n",
    "    #print probes to file\n",
    "    targeted_probes = []\n",
    "    for seq in seq_records:\n",
    "        locus=seq.name.split(\"_\")[2]\n",
    "        if locus in targeted_loci:\n",
    "            targeted_probes.append(seq)\n",
    "            \n",
    "    #write targeted_probes to file\n",
    "    out_probe_file = \"results/phyluce/targeted_probes/{}_50_loci_probes.fas\".format(group)\n",
    "    SeqIO.write(targeted_probes, out_probe_file, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make a test probe set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_file = \"results/phyluce/50_loci_probes.fas\"\n",
    "\n",
    "!cat results/phyluce/targeted_probes/*_50_loci_probes.fas >results/phyluce/{probe_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing contamints from Arbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got a list of \"contaminating\" probes from Arbor and need to replace those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"results/phyluce/targeted_probes_post_contam_filtering\"):\n",
    "    shutil.rmtree(\"results/phyluce/targeted_probes_post_contam_filtering\")\n",
    "\n",
    "os.makedirs(\"results/phyluce/targeted_probes_post_contam_filtering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of loci needed per group\n",
    "with open('data/Probes_to_remove.txt', 'r',) as f:\n",
    "    contam_probes = f.readlines()\n",
    "    \n",
    "contam_probes = [x.rstrip() for x in contam_probes]\n",
    "# contam_probes = [x.rstrip() for x in contam_probes]\n",
    "\n",
    "contam_loci = []\n",
    "for probe in contam_probes:\n",
    "    locus = \"_\".join(probe.split(\"_\")[0:3])\n",
    "    contam_loci.append(locus)\n",
    "    \n",
    "contam_loci = list(set(contam_loci))\n",
    "contam_loci.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get 50 loci with the fewest numbers of probes\n",
    "\n",
    "for group in major_groups:\n",
    "    in_clust_fas = \"results/phyluce/{}/final_probe_design/{}_v1-master_probe_list.95P_cdhit\".format( group, \n",
    "                                                                                                     group )\n",
    "    #count number of probes per locus\n",
    "    #read in the sequences\n",
    "    seq_records = list(SeqIO.parse(in_clust_fas, \"fasta\"))\n",
    "    \n",
    "    locus_counts = defaultdict(int)\n",
    "    locus_names = {}\n",
    "    \n",
    "    #loop through the sequences and count the number of probes per locus\n",
    "    for seq in seq_records:\n",
    "        locus=\"_\".join(seq.name.split(\"_\")[0:3])\n",
    "        locus_counts[locus] = locus_counts[locus] + 1\n",
    "    \n",
    "    #get loci sorted by num probes \n",
    "    loci_sorted_by_n_probes = sorted(locus_counts.items(), key=lambda x: x[1])\n",
    "    loci_sorted_by_n_probes = [x[0] for x in loci_sorted_by_n_probes]\n",
    "    \n",
    "    #remove contaminated loci\n",
    "    for probe in contam_loci:\n",
    "        if probe in loci_sorted_by_n_probes:\n",
    "            loci_sorted_by_n_probes.remove(probe)\n",
    "\n",
    "    #now get top 48\n",
    "    target_loci = loci_sorted_by_n_probes[0:49]\n",
    "    \n",
    "    targeted_probes = []\n",
    "    for seq in seq_records:\n",
    "        locus=\"_\".join(seq.name.split(\"_\")[0:3])\n",
    "        if locus in target_loci:\n",
    "            targeted_probes.append(seq)\n",
    "            \n",
    "    #write targeted_probes to file\n",
    "    out_probe_file = \"results/phyluce/targeted_probes_post_contam_filtering/{}_48_loci_probes.fas\".format(group)\n",
    "    SeqIO.write(targeted_probes, out_probe_file, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat results/phyluce/targeted_probes_post_contam_filtering/*_48_loci_probes.fas >results/phyluce/decon_probes.fas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# E-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"results/peer_validation\"):\n",
    "    shutil.rmtree(\"results/peer_validation\")\n",
    "\n",
    "os.makedirs(\"results/peer_validation/sra_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "all the seq data from PRJEB35488 was stored in a file ```results/phyluce/peer_validation/sra_data/SraAccList.txt``` and used to download the SRA files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "peromyscus_samples = { \"peer099\" : \"ERR3672161\",   \"peer098\" : \"ERR3672162\",\n",
    "                       \"peer095\" : \"ERR3672163\",   \"peer093\" : \"ERR3672164\",\n",
    "                       \"peer092\" : \"ERR3672165\",   \"peer091\" : \"ERR3672166\",\n",
    "                       \"peer075\" : \"ERR3672167\",   \"peer339\" : \"ERR3672168\",\n",
    "                       \"peer338\" : \"ERR3672169\",   \"peer336\" : \"ERR3672170\",\n",
    "                       \"peer335\" : \"ERR3672171\",   \"peer334\" : \"ERR3672172\",\n",
    "                       \"peer333\" : \"ERR3672173\",   \"peer330\" : \"ERR3672174\",\n",
    "                       \"peer326\" : \"ERR3672175\",   \"peer305\" : \"ERR3672176\",\n",
    "                       \"peer017\" : \"ERR3672177\",   \"peer016\" : \"ERR3672178\",\n",
    "                       \"peer015\" : \"ERR3672179\",   \"peer144\" : \"ERR3672180\",\n",
    "                       \"peer139\" : \"ERR3672181\",   \"peer138\" : \"ERR3672182\",\n",
    "                       \"peer136\" : \"ERR3672183\",   \"peer135\" : \"ERR3672184\",\n",
    "                       \"peer134\" : \"ERR3672185\",   \"peer012\" : \"ERR3672186\"  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Download the data\n",
    "\n",
    "This takes a LONG LONG time (~1 day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-02-20T17:09:42 prefetch.2.8.0: 1) 'ERR3672161' is found locally\n",
      "\n",
      "2020-02-20T17:09:42 prefetch.2.8.0: 2) 'ERR3672162' is found locally\n",
      "\n",
      "2020-02-20T17:09:43 prefetch.2.8.0: 3) 'ERR3672163' is found locally\n",
      "\n",
      "2020-02-20T17:09:43 prefetch.2.8.0: 4) 'ERR3672164' is found locally\n",
      "\n",
      "2020-02-20T17:09:44 prefetch.2.8.0: 5) 'ERR3672165' is found locally\n",
      "\n",
      "2020-02-20T17:09:44 prefetch.2.8.0: 6) 'ERR3672166' is found locally\n",
      "\n",
      "2020-02-20T17:09:45 prefetch.2.8.0: 7) 'ERR3672167' is found locally\n",
      "\n",
      "2020-02-20T17:09:45 prefetch.2.8.0: 8) 'ERR3672168' is found locally\n",
      "\n",
      "2020-02-20T17:09:45 prefetch.2.8.0: 9) 'ERR3672169' is found locally\n",
      "\n",
      "2020-02-20T17:09:46 prefetch.2.8.0: 10) 'ERR3672170' is found locally\n",
      "\n",
      "2020-02-20T17:09:46 prefetch.2.8.0: 11) 'ERR3672171' is found locally\n",
      "\n",
      "2020-02-20T17:09:47 prefetch.2.8.0: 12) 'ERR3672172' is found locally\n",
      "\n",
      "2020-02-20T17:09:47 prefetch.2.8.0: 13) 'ERR3672173' is found locally\n",
      "\n",
      "2020-02-20T17:09:48 prefetch.2.8.0: 14) 'ERR3672174' is found locally\n",
      "\n",
      "2020-02-20T17:09:48 prefetch.2.8.0: 15) 'ERR3672175' is found locally\n",
      "\n",
      "2020-02-20T17:09:49 prefetch.2.8.0: 16) 'ERR3672176' is found locally\n",
      "\n",
      "2020-02-20T17:09:49 prefetch.2.8.0: 17) 'ERR3672177' is found locally\n",
      "\n",
      "2020-02-20T17:09:49 prefetch.2.8.0: 18) 'ERR3672178' is found locally\n",
      "\n",
      "2020-02-20T17:09:50 prefetch.2.8.0: 19) 'ERR3672179' is found locally\n",
      "\n",
      "2020-02-20T17:09:50 prefetch.2.8.0: 20) 'ERR3672180' is found locally\n",
      "\n",
      "2020-02-20T17:09:51 prefetch.2.8.0: 21) 'ERR3672181' is found locally\n",
      "\n",
      "2020-02-20T17:09:51 prefetch.2.8.0: 22) 'ERR3672182' is found locally\n",
      "\n",
      "2020-02-20T17:09:52 prefetch.2.8.0: 23) 'ERR3672183' is found locally\n",
      "\n",
      "2020-02-20T17:09:52 prefetch.2.8.0: 24) 'ERR3672184' is found locally\n",
      "\n",
      "2020-02-20T17:09:53 prefetch.2.8.0: 25) 'ERR3672185' is found locally\n",
      "\n",
      "2020-02-20T17:09:53 prefetch.2.8.0: 26) 'ERR3672186' is found locally\n"
     ]
    }
   ],
   "source": [
    "!prefetch --option-file data/SraAccList.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Convert to fas and randomize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job 5489754 (\"random_ERR3672161\") has been submitted\n",
      "Your job 5489755 (\"random_ERR3672162\") has been submitted\n",
      "Your job 5489756 (\"random_ERR3672163\") has been submitted\n",
      "Your job 5489757 (\"random_ERR3672164\") has been submitted\n",
      "Your job 5489758 (\"random_ERR3672165\") has been submitted\n",
      "Your job 5489759 (\"random_ERR3672166\") has been submitted\n",
      "Your job 5489760 (\"random_ERR3672167\") has been submitted\n",
      "Your job 5489761 (\"random_ERR3672168\") has been submitted\n",
      "Your job 5489762 (\"random_ERR3672169\") has been submitted\n",
      "Your job 5489763 (\"random_ERR3672170\") has been submitted\n",
      "Your job 5489764 (\"random_ERR3672171\") has been submitted\n",
      "Your job 5489765 (\"random_ERR3672172\") has been submitted\n",
      "Your job 5489766 (\"random_ERR3672173\") has been submitted\n",
      "Your job 5489767 (\"random_ERR3672174\") has been submitted\n",
      "Your job 5489768 (\"random_ERR3672175\") has been submitted\n",
      "Your job 5489769 (\"random_ERR3672176\") has been submitted\n",
      "Your job 5489770 (\"random_ERR3672177\") has been submitted\n",
      "Your job 5489771 (\"random_ERR3672178\") has been submitted\n",
      "Your job 5489772 (\"random_ERR3672179\") has been submitted\n",
      "Your job 5489773 (\"random_ERR3672180\") has been submitted\n",
      "Your job 5489774 (\"random_ERR3672181\") has been submitted\n",
      "Your job 5489775 (\"random_ERR3672182\") has been submitted\n",
      "Your job 5489776 (\"random_ERR3672183\") has been submitted\n",
      "Your job 5489777 (\"random_ERR3672184\") has been submitted\n",
      "Your job 5489778 (\"random_ERR3672185\") has been submitted\n",
      "Your job 5489779 (\"random_ERR3672186\") has been submitted\n"
     ]
    }
   ],
   "source": [
    "for sample in peromyscus_samples:\n",
    "    \n",
    "    #for each sample, cover the sra a to fasta\n",
    "    accession = peromyscus_samples[sample]\n",
    "    dump_cmd = \"fastq-dump --split-spot --outdir results/peer_validation/sra_data/ --split-files --fasta 0 {}; \".format(accession)\n",
    "    subprocess.run(cmd.split(\" \"))\n",
    "    \n",
    "    #combine into a single fasta\n",
    "    r1_fas   = \"results/peer_validation/sra_data/\" + accession + \"_1.fasta\"\n",
    "    r2_fas   = \"results/peer_validation/sra_data/\" + accession + \"_2.fasta\"\n",
    "    comb_fas = \"results/peer_validation/sra_data/\" + accession + \".fasta\"\n",
    "\n",
    "    #combine\n",
    "    cat_cmd = \"cat {} {} >{}; \".format(r1_fas, r2_fas, comb_fas)\n",
    "    \n",
    "    #delete single end reads\n",
    "    rm_cmd = \"rm {} {}; \".format(r1_fas, r2_fas)\n",
    "    \n",
    "    #then take the fasta (raw reads) and randomize the nucleotide order per read\n",
    "    #  this creates a control, but maintains the GC% with muliple ranomizing passes per read\n",
    "    in_fasta  = \"results/peer_validation/sra_data/\" + accession + \".fasta\"\n",
    "    out_fasta = \"results/peer_validation/sra_data/\" + accession + \"_randomized.fasta\"\n",
    "    n_passes  = 5 \n",
    "    \n",
    "    random_cmd = \"python code/randomize_nucleotide_order.py {} {} {}; \".format(n_passes, in_fasta, out_fasta)\n",
    "    \n",
    "    #now set up qsub\n",
    "    jid= \"random_\" + accession\n",
    "    log= \"results/peer_validation/sra_data/\" + jid + \".log\"\n",
    "    qsub_cmd = \"qsub -V -cwd -S /bin/bash -q all.q -j y -N {} -o {} -pe smp 12\".format(jid, log)\n",
    "\n",
    "    #conda\n",
    "    conda_cmd = \"conda activate pathogen_probes; \"\n",
    "\n",
    "    #and submit to the queue\n",
    "    combined_cmd =\"echo \\\"\" + conda_cmd + dump_cmd + cat_cmd + rm_cmd + random_cmd + \"\\\" | \" + qsub_cmd\n",
    "    \n",
    "    #print(combined_cmd)\n",
    "    !{combined_cmd}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Build indexes and blast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"results/peer_validation/probe_blasts\"):\n",
    "    shutil.rmtree(\"results/peer_validation/probe_blasts\")\n",
    "\n",
    "os.makedirs(\"results/peer_validation/probe_blasts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#get the P. californicus genome\n",
    "ncbi_link = \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/007/827/085/GCA_007827085.1_PCal_1.0/GCA_007827085.1_PCal_1.0_genomic.fna.gz\"\n",
    "\n",
    "filename = wget.download(ncbi_link)\n",
    "os.rename(filename, \"results/peer_validation/probe_blasts/Pcal1.fas.gz\")\n",
    "\n",
    "#mv filename to appropriate directory\n",
    "!gunzip results/peer_validation/probe_blasts/Pcal1.fas.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#make probe set with pero genome\n",
    "probes_plus_genome_fas = \"results/peer_validation/probe_blasts/probes_and_Pcal1.fas\"\n",
    "\n",
    "#combine it with the probes to\n",
    "!cat results/peer_validation/probe_blasts/Pcal1.fas {probe_file} >{probes_plus_genome_fas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#index probes and genome\n",
    "subject_fas = probes_plus_genome_fas\n",
    "fas_db_cmd  = \"makeblastdb -dbtype nucl -in {}\".format(subject_fas)\n",
    "\n",
    "subprocess.run(fas_db_cmd.split(\" \"))\n",
    "\n",
    "\n",
    "for sample in peromyscus_samples:\n",
    "    accession = peromyscus_samples[sample]\n",
    "    \n",
    "    ##########################################################################################\n",
    "    in_fas     = \"results/peer_validation/sra_data/\" + accession + \".fasta\"\n",
    "    out_blast  = \"results/peer_validation/probe_blasts/\" + accession + \"_blast.out\"\n",
    "    blast_cmd = \"blastn -db {} -query {} -out {} -perc_identity 90 -outfmt 6 -num_threads 6\".format(subject_fas, \n",
    "                                                                                                    in_fas, \n",
    "                                                                                                    out_blast)\n",
    "    \n",
    "    #now set up qsub\n",
    "    jid= \"blast_\" + accession\n",
    "    log= \"results/peer_validation/probe_blasts/\" + jid + \".log\"\n",
    "    qsub_cmd = \"qsub -V -cwd -S /bin/bash -q all.q -j y -N {} -o {} -pe smp 12\".format(jid, log)\n",
    "\n",
    "    #conda\n",
    "    conda_cmd = \"conda activate pathogen_probes; \"\n",
    "\n",
    "    #and submit to the queue\n",
    "    combined_cmd =\"echo \\\"\" + conda_cmd + blast_cmd + \"\\\" | \" + qsub_cmd\n",
    "\n",
    "    #print(combined_cmd)\n",
    "    !{combined_cmd}\n",
    "    \n",
    "    ##########################################################################################\n",
    "    rand_fas   = \"results/peer_validation/sra_data/\" + accession + \"_randomized.fasta\"\n",
    "    rand_blast = \"results/peer_validation/probe_blasts/\" + accession + \"_randomized_blast.out\"\n",
    "    rand_cmd  = \"blastn -db {} -query {} -out {} -perc_identity 90 -outfmt 6 -num_threads 6\".format(subject_fas, \n",
    "                                                                                                    rand_fas, \n",
    "                                                                                                    rand_blast)\n",
    "    #now set up qsub\n",
    "    jid= \"blast_random_\" + accession\n",
    "    log= \"results/peer_validation/probe_blasts/\" + jid + \".log\"\n",
    "    qsub_cmd = \"qsub -V -cwd -S /bin/bash -q all.q -j y -N {} -o {} -pe smp 12\".format(jid, log)\n",
    "\n",
    "    #conda\n",
    "    conda_cmd = \"conda activate pathogen_probes; \"\n",
    "\n",
    "    #and submit to the queue\n",
    "    combined_cmd =\"echo \\\"\" + conda_cmd + blast_cmd + \"\\\" | \" + qsub_cmd\n",
    "\n",
    "    #print(combined_cmd)\n",
    "    !{combined_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for sample in peromyscus_samples:\n",
    "    accession = peromyscus_samples[sample]\n",
    "    \n",
    "    fasta      = \"results/peer_validation/sra_data/\" + accession + \".fasta\"\n",
    "    rand_fasta = \"results/peer_validation/sra_data/\" + accession + \"_randomized.fasta\"\n",
    "\n",
    "    \n",
    "    #submit to build blast index of real and random data\n",
    "    fas_db_cmd  = \"makeblastdb -dbtype nucl -in {}\".format(fasta)\n",
    "    rand_db_cmd = \"makeblastdb -dbtype nucl -in {}\".format(rand_fasta)\n",
    "    \n",
    "    #now set up qsub\n",
    "    jid= \"db_\" + accession\n",
    "    log= \"results/peer_validation/sra_data/\" + jid + \".log\"\n",
    "    qsub_cmd = \"qsub -V -cwd -S /bin/bash -q all.q -j y -N {} -o {} -pe smp 12\".format(jid, log)\n",
    "\n",
    "    #conda\n",
    "    conda_cmd = \"conda activate pathogen_probes; \"\n",
    "\n",
    "    #and submit to the queue\n",
    "    combined_cmd =\"echo \\\"\" + conda_cmd + random_cmd + \"\\\" | \" + qsub_cmd\n",
    "    \n",
    "    #print(combined_cmd)\n",
    "    !{combined_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Kraken2 the unfiltered reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test probes against several SRAs\n",
    "if os.path.exists(\"results/peer_validation/kraken2\"):\n",
    "    shutil.rmtree(\"results/peer_validation/kraken2\")\n",
    "\n",
    "os.makedirs(\"results/peer_validation/kraken2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#build Kraken2 db\n",
    "subprocess.rub(\"kraken2-build --standard --threads 6 --db results/peer_validation/kraken2_standard_db\", shell=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    #quanify/classify\n",
    "    kraken2 \\\n",
    "        --use-names \\\n",
    "        --threads 4 \\\n",
    "        --db kraken2_standard_db \\\n",
    "        --report kraken.out \\\n",
    "        reads.fa \\\n",
    "        >kraken.tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Do something to compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
